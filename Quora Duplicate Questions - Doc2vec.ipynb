{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import multiprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Cleaned Data from raw .tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files names - if these files and folders don't exist then they are downloaded \n",
    "raw_file_name = \"quora_duplicate_questions.tsv\"\n",
    "q1_file_name = \"cleaned_q1.txt\"\n",
    "q2_file_name = \"cleaned_q2.txt\"\n",
    "dup_file_name = \"is_duplicate.txt\"\n",
    "questions_folder_name = \"cleaned_data\"\n",
    "\n",
    "# file to store hyperparameter tuning numbers\n",
    "parameters_and_errors_name = \"test_parameters_and_errors.csv\"# \"parameters_and_errors.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import requests\n",
    "\n",
    "# check whether downloaded data already exists with names provided above\n",
    "if not os.path.isdir(questions_folder_name) or not os.path.isfile(dup_file_name):\n",
    "    \n",
    "    # Download questions file - data set has been changed since first release\n",
    "    url = 'http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv'\n",
    "    r = requests.get(url)\n",
    "    with open(raw_file_name, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    \n",
    "    # DATA CLEANING WITH PANDAS\n",
    "    \n",
    "    # read in file into dataframe\n",
    "    data = pd.read_csv(raw_file_name, sep='\\t')\n",
    "    # drop rows with null value\n",
    "    data.dropna(inplace=True)\n",
    "    # make columns of lower cased words\n",
    "    data[\"cleaned_q1\"] = data.text1.str.lower()\n",
    "    data[\"cleaned_q2\"] = data.text2.str.lower()\n",
    "    # remove punctuation from lower-cased words columns\n",
    "    data['cleaned_q1'] = data['cleaned_q1'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
    "    data['cleaned_q2'] = data['cleaned_q2'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
    "    # remove the character \"\\n\", which messes up the line delimiters in txt file\n",
    "    # these only occur ~20 times in the questions\n",
    "    data[\"cleaned_q1\"] = data['cleaned_q1'].str.replace(\"\\n\", \"\")\n",
    "    data[\"cleaned_q2\"] = data['cleaned_q2'].str.replace(\"\\n\", \"\")\n",
    "    # shuffle data before writing to file - this way random sample can be taken from file \n",
    "    # simply by choosing first n rows of file\n",
    "    data = data.sample(frac=1)\n",
    "\n",
    "    # create directory to hold question data\n",
    "    if not os.path.exists(questions_folder_name):\n",
    "        os.makedirs(questions_folder_name)\n",
    "\n",
    "    # write cleaned text rows to txt files, one line for each sentence\n",
    "    data[\"cleaned_q1\"].to_csv(questions_folder_name + \"/\" + q1_file_name, sep='\\n', header=False, index=False)\n",
    "    data[\"cleaned_q2\"].to_csv(questions_folder_name + \"/\" + q2_file_name, sep='\\n', header=False, index=False)\n",
    "    # write dup values to txt file, one line for each value\n",
    "    data[\"duplicate\"].to_csv(dup_file_name, sep='\\n', header=False, index=False)\n",
    "\n",
    "    print \"Saved file with\", len(data), \"rows at\", raw_file_name\n",
    "else: \n",
    "    print \"Directory that should contain data already exists.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notebook assumes you have a directory \"questions_directory\" that contains two text files, one for all \n",
    "# first questions and one for all second questions, and a file is_dup_file that has one boolean value (0 or 1)\n",
    "# on each line, one for all ~400,000 document pairs that tells whether questions are duplicates or not\n",
    "\n",
    "# path to questions directory (contains sorted question text files) and \n",
    "# is_dup_file (contains sorted answers about whether question pairs are duplicates)\n",
    "\n",
    "# These files and directories are created automatically by the above cell\n",
    "questions_directory = questions_folder_name\n",
    "is_dup_file = dup_file_name\n",
    "questions_file_names = [os.path.basename(filename) for filename in os.listdir(questions_directory)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions_file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set number of rows (question pairs) to train on\n",
    "num_question_pairs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# produce logs during training\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "rootLogger = logging.getLogger()\n",
    "rootLogger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create iterator to run through directory of text files with one sentence per line\n",
    "from itertools import izip, count\n",
    "\n",
    "# class that iterates through first \"rows\" lines of questions list (\"rows\" is integer)\n",
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, dirname, rows=None):\n",
    "        self.dirname = dirname\n",
    "        self.rows = rows\n",
    "    def __iter__(self):\n",
    "        for filename in os.listdir(self.dirname):\n",
    "            for uid, text_line in enumerate(open(os.path.join(self.dirname, filename))):\n",
    "                if self.rows:\n",
    "                    if uid >= self.rows: \n",
    "                        break\n",
    "            # for uid, line in enumerate(open(os.path.join(self.dirname, filename))):\n",
    "                yield gensim.models.doc2vec.LabeledSentence(words=text_line.split(), tags=[os.path.basename(filename) + '_%s' % uid])\n",
    "\n",
    "# make sure using fast version\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1\n",
    "cores = multiprocessing.cpu_count() # number of cores on computer to use for computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load in data into memory - all data combined should only be 200-300 megabytes\n",
    "# this is done instead of using iterator - makes doing shuffles of data easier\n",
    "\n",
    "all_docs = []\n",
    "sentences = LabeledLineSentence(questions_directory, rows=num_question_pairs)\n",
    "for sentence in sentences:\n",
    "    all_docs.append(sentence)\n",
    "\n",
    "print('%d question pairs to train (%d documents total)' % (num_question_pairs, len(all_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make list of tuples (document1, document2, is_dup) for all num_question_pairs\n",
    "# the document names come from naming scheme used in LabeledLineSentence class \n",
    "\n",
    "doc_names_and_duplicate_class = []\n",
    "for i, line in enumerate(open(is_dup_file)):\n",
    "    if i >= num_question_pairs:\n",
    "        break\n",
    "    doc_tup = (questions_file_names[0] + \"_\" + str(i), questions_file_names[1] + \"_\" + str(i), int(line.strip(\"\\n\")))\n",
    "    doc_names_and_duplicate_class.append(doc_tup)\n",
    "\n",
    "print len(doc_names_and_duplicate_class), \"document pairs to classify\"\n",
    "print \"Document pair names and labels contained in doc_names_and_duplicate_class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_names_and_duplicate_class[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calculate_AUC(model, doc_names_and_duplicate_class): \n",
    "    \"\"\" Return area under ROC curve for model. This is done by simply taking cosine similarity between \n",
    "        document vectors to predict whether they are duplicate questions or not.\n",
    "    \"\"\"\n",
    "    doc_distances = []\n",
    "\n",
    "    for i in range(len(doc_names_and_duplicate_class)):\n",
    "        # get word vectors for given pair\n",
    "        vec1_name = doc_names_and_duplicate_class[i][0]\n",
    "        vec2_name = doc_names_and_duplicate_class[i][1]\n",
    "        vec1 = model.docvecs[vec1_name]         \n",
    "        vec2 = model.docvecs[vec2_name]       \n",
    "        # take cosine distance between them\n",
    "        distance = cosine_similarity(vec1, vec2)\n",
    "        doc_distances.append(distance)\n",
    "\n",
    "    doc_distances = np.array(doc_distances)\n",
    "    doc_scores = np.array([x[2] for x in doc_names_and_duplicate_class])\n",
    "    \n",
    "    return roc_auc_score(doc_scores, doc_distances)\n",
    "\n",
    "def cosine_similarity(vec1, vec2): \n",
    "    # return cosine angle between numpy vectors v1 and v2\n",
    "    def unit_vector(vec):\n",
    "        return vec/np.linalg.norm(vec)\n",
    "    vec1_u, vec2_u = unit_vector(vec1), unit_vector(vec2)\n",
    "    return np.dot(vec1_u, vec2_u)\n",
    "\n",
    "# for timing\n",
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "import time \n",
    "\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = default_timer()\n",
    "    elapser = lambda: default_timer() - start\n",
    "    yield lambda: elapser()\n",
    "    end = default_timer()\n",
    "    elapser = lambda: end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize Doc2vec model parameters\n",
    "\"\"\"\n",
    "The documents iterable can be simply a list of TaggedDocument elements, \n",
    "but for larger corpora, consider an iterable that streams the documents \n",
    "directly from disk/network.\n",
    "\n",
    "If you don’t supply documents, the model is left uninitialized – \n",
    "use if you plan to initialize it in some other way.\n",
    "\n",
    "\n",
    "\n",
    "dm defines the training algorithm. By default (dm=1), \n",
    "    ‘distributed memory’ (PV-DM) is used. Otherwise, distributed bag of words (PV-DBOW) is employed.\n",
    "\n",
    "size is the dimensionality of the feature vectors.\n",
    "\n",
    "window is the maximum distance between the predicted word and context words used for prediction within a document.\n",
    "\n",
    "alpha is the initial learning rate (will linearly drop to zero as training progresses).\n",
    "\n",
    "seed = for the random number generator. Note that for a fully deterministically-reproducible run, \n",
    "    you must also limit the model to a single worker thread, to eliminate ordering jitter from \n",
    "    OS thread scheduling. (In Python 3, reproducibility between interpreter launches also \n",
    "    requires use of the PYTHONHASHSEED environment variable to control hash randomization.)\n",
    "\n",
    "min_count = ignore all words with total frequency lower than this.\n",
    "\n",
    "max_vocab_size = limit RAM during vocabulary building; if there are more unique words \n",
    "                 than this, then prune the infrequent ones. Every 10 million word types \n",
    "                 need about 1GB of RAM. Set to None for no limit (default).\n",
    "\n",
    "sample = threshold for configuring which higher-frequency words are randomly downsampled;\n",
    "        default is 0 (off), useful value is 1e-5.\n",
    "        \n",
    "workers = use this many worker threads to train the model (=faster training with multicore machines).\n",
    "\n",
    "iter = number of iterations (epochs) over the corpus. The default inherited from Word2Vec is 5, \n",
    "        but values of 10 or 20 are common in published ‘Paragraph Vector’ experiments.\n",
    "\n",
    "hs = if 1 (default), hierarchical sampling will be used for model training (else set to 0).\n",
    "\n",
    "negative = if > 0, negative sampling will be used, the int for negative specifies how many \n",
    "            “noise words” should be drawn (usually between 5-20).\n",
    "\n",
    "dm_mean = if 0 (default), use the sum of the context word vectors. If 1, use the mean. \n",
    "            Only applies when dm is used in non-concatenative mode.\n",
    "\n",
    "dm_concat = if 1, use concatenation of context vectors rather than sum/average; default is 0 (off). \n",
    "                Note concatenation results in a much-larger model, as the input is no longer the size of \n",
    "                one (sampled or arithmatically combined) word vector, but the size of the tag(s) and all \n",
    "                words in the context strung together.\n",
    "\n",
    "dm_tag_count = expected constant number of document tags per document, when using dm_concat mode; default is 1.\n",
    "\n",
    "dbow_words if set to 1 trains word-vectors (in skip-gram fashion) simultaneous with DBOW doc-vector training; \n",
    "            default is 0 (faster training of doc-vectors only).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# set model parameters parameters\n",
    "\n",
    "parameters_dict = {\n",
    "\n",
    "'documents' : all_docs,\n",
    "'dm' : 0, # use bag-of-words (dbow) model; 1 uses embedding (dmpv) model\n",
    "'size' : 200, # size of word/doc vectors\n",
    "'window' : 15, # # max distance between word and neighbor word for word embeddings\n",
    "'alpha' : .025, # learning rate - use rate in paper\n",
    "'min_alpha' : 0.0001, # rate from paper\n",
    "'min_count' : 5, # ignore words with count less than this\n",
    "'sample' : 1e-5, # how to configure downsampling for high frequency words\n",
    "'workers' : cores, # number of cores to use\n",
    "'hs' : 0, # use negative sampling\n",
    "'negative' : 5, # used in negative sampling\n",
    "'dbow_words' : 1, # trains word vectors in addition to document vectors in dbow model\n",
    "'iter' : 3 # recommended number of epochs is ~20 for dbow model on question comparison   \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create parameters for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create list of parameters to use in model\n",
    "dms = [0]\n",
    "sizes = [300]\n",
    "windows = [5, 15]\n",
    "alphas = [0.025]\n",
    "min_alphas = [0.0001]\n",
    "min_counts = [1, 5]\n",
    "samples = [1e-5, 0.5e-5, 1e-6]\n",
    "workers_s = [cores]\n",
    "hs_s = [0]\n",
    "negatives = [5]\n",
    "dbow_words_s = [1]\n",
    "iters = [150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run through all parameters and record error rate of each one\n",
    "from itertools import product\n",
    "\n",
    "# create list to score ROC AUC scores and their model parameters\n",
    "params_and_errors = []\n",
    "# create iterable of all combinations of parameters\n",
    "params_product = product(dms, sizes, windows, alphas, min_alphas, \n",
    "                        min_counts, samples, workers_s, hs_s, negatives, \n",
    "                        dbow_words_s, iters)\n",
    "parameters = [x for x in params_product]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Starting first run of\", len(parameters), \"runs\"\n",
    "total_time = 0\n",
    "for run_number, pars in enumerate(parameters): \n",
    "    params = {'dm':pars[0], 'size':pars[1], 'window':pars[2], \n",
    "              'alpha':pars[3], 'min_alpha':pars[4], 'min_count':pars[5],\n",
    "              'sample':pars[6], 'workers':pars[7], 'hs':pars[8],\n",
    "              'negative':pars[9], 'dbow_words':pars[10], 'iter':pars[11]}\n",
    "    with elapsed_timer() as elapsed:\n",
    "        model = gensim.models.doc2vec.Doc2Vec(documents=all_docs, **params)\n",
    "        AUC_value = calculate_AUC(model, doc_names_and_duplicate_class)\n",
    "        params_and_errors.append((params, AUC_value))\n",
    "        duration = '%.1f' % elapsed()\n",
    "        total_time += float(duration)\n",
    "        print \n",
    "        print \"Completed run number\", run_number + 1, \"of\", len(parameters), \"runs total\"\n",
    "        print \"AUC score:\", round(AUC_value, 4)\n",
    "        print \"Training for this run took\", round(float(duration)/60.,1), \"minutes\"\n",
    "\n",
    "best_AUC = max([x[1] for x in params_and_errors])\n",
    "print\n",
    "print\n",
    "print \"Total training time for all runs:\", round(float(total_time)/3600.,2), \"hours\"\n",
    "print \"Best AUC value:\", round(best_AUC, 6)\n",
    "print \"Paramters for best AUC value:\", [x[0] for x in params_and_errors if x[1] == best_AUC][0]\n",
    "\n",
    "# convert params and errors into easy-to-read pandas dataframe\n",
    "params_df = pd.DataFrame([x[0] for x in params_and_errors])\n",
    "params_df[\"AUC\"] = pd.Series([x[1] for x in params_and_errors])\n",
    "params_df.sort_values(\"AUC\", ascending=False, inplace=True)\n",
    "\n",
    "# write parameter values to csv - append if this csv already exists\n",
    "header=True\n",
    "if os.path.isfile(parameters_and_errors_name):\n",
    "    header=False\n",
    "params_df.to_csv(parameters_and_errors_name, header=header, index=False, mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show only the columns that changed in value \n",
    "params_df.loc[:, (params_df != params_df.ix[0]).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" PARAMETER TIPS: \n",
    "\n",
    "sample: CRITICAL: 1e-6 terrible, 5e-6 and 1e-5 better - try 5e-5 \n",
    "min_count: 1 works well with small data set\n",
    "window: 5 and 15 both worked reasonably well\n",
    "size: 300 works well\n",
    "iter: 150 seems ok, try more - sentence similarity in paper used ~400 to converge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in paramater file to see what has been done before\n",
    "all_params_df = pd.read_csv(parameters_and_errors_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.672 with 100-length vectors and 20 epochs\n",
    "# 0.671 with 300-length vectors and 20 epochs\n",
    "# 0.74 with 200-length vectors and 200 epochs\n",
    "# 0.74 with 200-length vectors and 100 epochs\n",
    "\n",
    "# model seems to tail off in accuracy around 100 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual runs with accuracy check at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try a run with manual epochs and recording accuracy after each epoch\n",
    "model = gensim.models.doc2vec.Doc2Vec(documents=None, dm=dm, size=size, window=window, \n",
    "                                      alpha=alpha, min_alpha=min_alpha, min_count=min_count, \n",
    "                                      sample=sample, workers=workers, hs=hs, negative=negative, \n",
    "                                      dbow_words=dbow_words, iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "# number of epochs to train\n",
    "# need to manually decrease alpha in this case\n",
    "epochs = 100\n",
    "alpha = 0.025\n",
    "min_alpha = 0.0001\n",
    "alpha_delta = (alpha - min_alpha) / epochs\n",
    "\n",
    "model.build_vocab(all_docs)\n",
    "with elapsed_timer() as elapsed:\n",
    "    for epoch in range(epochs): \n",
    "        model.alpha, model.min_alpha = alpha, alpha\n",
    "        # shuffle documents\n",
    "        shuffle(all_docs)\n",
    "        # train model\n",
    "        model.train(all_docs)\n",
    "        # evaluate model \n",
    "        error = calculate_AUC(model, doc_names_and_duplicate_class)\n",
    "        alpha -= alpha_delta\n",
    "        print \"AUC for epoch\", epoch, \":\", error\n",
    "    duration = '%.1f' % elapsed()\n",
    "    print(\"completed training in %s minutes\" % (duration/60.))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
